{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\"\n",
    "    initialize the grid world environemnt\n",
    "    \"\"\"\n",
    "    def __init__(self, height=7, width=7):\n",
    "        \n",
    "        # setting up the grid world\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.rewards = np.zeros((self.height, self.width)) - 1\n",
    "        self.rewards[0,0] = 20\n",
    "        \n",
    "        # set random start state (or location) for the agent\n",
    "        self.current_state = (self.height-1, 0)\n",
    "        \n",
    "        # set states (or locations) for the bomb and the gold\n",
    "        self.gold_state = (0,0)\n",
    "        self.terminal_states = [self.gold_state]\n",
    "        self.obstacle = [(2,0),(2,1),(2,2),(2,3),(2,4),(2,5)]\n",
    "        # set grid rewards for bomb and gold states\n",
    "        \n",
    "        # the set of available actions\n",
    "        self.actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']   \n",
    "        \n",
    "    def get_actions(self):\n",
    "        \"\"\"\n",
    "        return the set of actions (A)\n",
    "        \"\"\"\n",
    "        return self.actions\n",
    "    \n",
    "    def get_agent_location(self):\n",
    "        \"\"\"\n",
    "        returns the current location of the agent marked on the grid world as ``1''\n",
    "        \"\"\"\n",
    "        grid_world = np.zeros((self.height, self.width))\n",
    "        grid_world[self.current_state[0], self.current_state[1]] = 1\n",
    "        return grid_world\n",
    "    \n",
    "    def get_reward(self, state):\n",
    "        \"\"\"\n",
    "        returns the reward for the input state\n",
    "        \"\"\"\n",
    "        return self.rewards[state[0], state[1]]\n",
    "        \n",
    "    \n",
    "    def delta(self, action):\n",
    "        \"\"\"\n",
    "        moves the agent in the specified direction: if agent is at a border then it stays still\n",
    "        but takes negative reward and the function returns the immediate reward for the action\n",
    "        \"\"\"\n",
    "        # store the location before taking action\n",
    "        last_state = self.current_state\n",
    "        \n",
    "        # move UP\n",
    "        if action == 'UP':\n",
    "            # if the agent is at the top border, stay still, collect negative reward\n",
    "            new_pos = (last_state[0]-1,last_state[1])\n",
    "            if new_pos in self.obstacle:\n",
    "                reward = self.get_reward(last_state)\n",
    "            elif last_state[0] == 0:\n",
    "                reward = self.get_reward(last_state)\n",
    "            else:\n",
    "                self.current_state = (self.current_state[0] - 1, self.current_state[1])\n",
    "                reward = self.get_reward(self.current_state)\n",
    "                \n",
    "        # move DOWN\n",
    "        elif action == 'DOWN':\n",
    "            new_pos = (last_state[0] +1,last_state[1])\n",
    "            # if the agent is at the bottom border, stay still, collect negative reward\n",
    "            if new_pos in self.obstacle:\n",
    "                reward = self.get_reward(last_state)\n",
    "            elif last_state[0] == self.height - 1:\n",
    "                reward = self.get_reward(last_state)\n",
    "            else:\n",
    "                self.current_state = (self.current_state[0] + 1, self.current_state[1])\n",
    "                reward = self.get_reward(self.current_state)\n",
    "            \n",
    "        # move LEFT\n",
    "        elif action == 'LEFT':\n",
    "            new_pos = (last_state[0],last_state[1]-1)\n",
    "\n",
    "            # if the agent is at the left border, stay still, collect negative reward\n",
    "            if new_pos in self.obstacle:\n",
    "                reward = self.get_reward(last_state)\n",
    "            elif last_state[1] == 0:\n",
    "                reward = self.get_reward(last_state)\n",
    "            else:\n",
    "                self.current_state = (self.current_state[0], self.current_state[1] - 1)\n",
    "                reward = self.get_reward(self.current_state)\n",
    "\n",
    "        # move RIGHT\n",
    "        elif action == 'RIGHT':\n",
    "            # of the agent is at the right border, stay still, collect negative reward\n",
    "            new_pos = (last_state[0],last_state[1]+1)\n",
    "            if new_pos in self.obstacle:\n",
    "                reward = self.get_reward(last_state)\n",
    "            elif last_state[1] == self.width - 1:\n",
    "                reward = self.get_reward(last_state)\n",
    "            else:\n",
    "                self.current_state = (self.current_state[0], self.current_state[1] + 1)\n",
    "                reward = self.get_reward(self.current_state)\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def check_state(self):\n",
    "        \"\"\"\n",
    "        check if the agent is in a terminal state (gold or bomb):\n",
    "        if so return 'TERMINAL', otherwise return 'NONTERMINAL'\n",
    "        \"\"\"\n",
    "        current_state_type = 'NONTERMINAL'\n",
    "        if self.current_state in self.terminal_states:\n",
    "            current_state_type ='TERMINAL'\n",
    "        \n",
    "        return current_state_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self):\n",
    "        np.random.seed(7)\n",
    "        self.time = -1\n",
    "    # select a random action\n",
    "    def select_action(self, actions):\n",
    "        \"\"\"\n",
    "        returns a random action\n",
    "        \"\"\"\n",
    "        self.time += 1 \n",
    "        return np.random.choice(actions)  \n",
    "    def reset(self):\n",
    "        self.time = -1\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimalPath:\n",
    "    def __init__(self):\n",
    "        self.choices = ['RIGHT','RIGHT','RIGHT','RIGHT','RIGHT','RIGHT','UP','UP','UP','UP','UP','UP','LEFT','LEFT','LEFT','LEFT','LEFT','LEFT']\n",
    "        self.time = -1\n",
    "    # select a random action\n",
    "    def select_action(self, actions):\n",
    "        \"\"\"\n",
    "        returns a random action\n",
    "        \"\"\"\n",
    "        self.time += 1\n",
    "        return self.choices[self.time]\n",
    "    def reset(self):\n",
    "        self.time = -1\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(agent, gamma=1.0, num_episodes=20, max_steps_per_episode=50, update_Q=False):\n",
    "    \"\"\"\n",
    "    the learn function plays episodes and updates Q-values\n",
    "    \"\"\"\n",
    "    np.random.seed(7)\n",
    "    path = []\n",
    "    reward_per_episode = [] # initialise performance log    \n",
    "    for episode in range(num_episodes): # run episodes\n",
    "        environment = Environment()\n",
    "        cumulative_reward = 0 # initialise cumulative reward of each episode\n",
    "        step = 0\n",
    "        episode_over = False\n",
    "        path = [(6,0)]\n",
    "        while step < max_steps_per_episode and episode_over != True: # run until max steps or until episode is over\n",
    "            current_state = environment.current_state\n",
    "            action = agent.select_action(environment.actions) \n",
    "            reward = environment.delta(action)\n",
    "            new_state = environment.current_state\n",
    "            path.append(new_state)\n",
    "            if update_Q == True: # update Q-values if learning is specified\n",
    "                agent.update(current_state, reward, new_state, action)\n",
    "                \n",
    "            cumulative_reward += reward * (gamma**step)\n",
    "            step += 1\n",
    "            if environment.check_state() == 'TERMINAL': # if agent is in terminal state, the episode is over and start the next episode\n",
    "                agent.reset()\n",
    "                environment.__init__()\n",
    "                episode_over = True\n",
    "        reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log\n",
    "        \n",
    "    return reward_per_episode,path # return episode log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal rewards:  3.0 [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0] \n",
      " random rewards:  -50.0 [-50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0, -50.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Optimal</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Optimal  Random\n",
       "0      3.0   -50.0\n",
       "1      3.0   -50.0\n",
       "2      3.0   -50.0\n",
       "3      3.0   -50.0\n",
       "4      3.0   -50.0"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ran_agent = RandomAgent()\n",
    "opt_agent = optimalPath()\n",
    "iters  = 20\n",
    "optimal_episode,opt_path = learn( opt_agent, num_episodes = iters)\n",
    "ran_episode,ran_path = learn( ran_agent, num_episodes = iters)\n",
    "print('optimal rewards: ',sum(optimal_episode)/20,optimal_episode,'\\n random rewards: ',sum(ran_episode)/20,ran_episode)\n",
    "rewards_df = pd.DataFrame(columns = ['Optimal','Random'])\n",
    "rewards_df['Optimal'] = optimal_episode\n",
    "rewards_df['Random'] = ran_episode\n",
    "rewards_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Average Acc Return')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (12,12))\n",
    "sns.barplot(data = rewards_df ).set_title('Average Acc Return')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 0), (6, 1), (5, 1), (6, 1), (6, 0), (6, 1), (6, 2), (6, 3), (6, 4), (5, 4), (6, 4), (6, 3), (6, 4), (5, 4), (6, 4), (6, 3), (6, 2), (6, 1), (5, 1), (5, 2), (5, 1), (4, 1), (3, 1), (3, 2), (3, 3), (3, 3), (3, 3), (3, 4), (3, 5), (3, 4), (3, 3), (3, 4), (3, 4), (3, 4), (3, 5), (4, 5), (3, 5), (3, 5), (3, 6), (4, 6), (3, 6), (3, 6), (4, 6), (3, 6), (3, 5), (3, 5), (4, 5), (4, 4), (4, 3), (3, 3), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(ran_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    height = 700\n",
    "    width = 700\n",
    "    image = Image.new(mode='RGB', size=(height, width), color=(255,255,255))\n",
    "\n",
    "    # Draw some lines\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    y_start = 0\n",
    "    y_end = image.height\n",
    "    step_size = int(image.width / 7)\n",
    "\n",
    "    for x in range(0, image.width, step_size):\n",
    "        line = ((x, y_start), (x, y_end))\n",
    "        draw.line(line, fill=128)\n",
    "\n",
    "    x_start = 0\n",
    "    x_end = image.width\n",
    "\n",
    "# draw text, half opacity\n",
    "\n",
    "    for y in range(0, image.height, step_size):\n",
    "        line = ((x_start, y), (x_end, y))\n",
    "        draw.line(line, fill=128)\n",
    "    for i,state in enumerate(opt_path[:-1]):\n",
    "        line = ((state[1]*100+50,state[0]*100+50),(opt_path[i+1][1]*100+50,opt_path[i+1][0]*100+50))\n",
    "        draw.line(line,fill='red',width = 15)\n",
    "        draw.text((state[1]*100+i,state[0]*100+20+i),str(i),fill='red')\n",
    "    for i,state in enumerate(ran_path[:-1]):\n",
    "        line = ((state[1]*100+30,state[0]*100+30),(ran_path[i+1][1]*100+30,ran_path[i+1][0]*100+30))\n",
    "        draw.line(line,fill='blue',width = 5)\n",
    "        ii = str(i)+' '\n",
    "        draw.text((state[1]*100,state[0]*100),ii,fill = 'blue')\n",
    "    #draw.line(((0,0),(600,600)),fill=128,width = 10)\n",
    "    draw.text((0,0),'Optimal Path',fill='red')\n",
    "    draw.text((0,20),'Random Path',fill='blue')\n",
    "    del draw\n",
    "\n",
    "    image.save('Path_Taken.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Creates a new image with the given mode and size.\n",
       "\n",
       ":param mode: The mode to use for the new image. See:\n",
       "   :ref:`concept-modes`.\n",
       ":param size: A 2-tuple, containing (width, height) in pixels.\n",
       ":param color: What color to use for the image.  Default is black.\n",
       "   If given, this should be a single integer or floating point value\n",
       "   for single-band modes, and a tuple for multi-band modes (one value\n",
       "   per band).  When creating RGB images, you can also use color\n",
       "   strings as supported by the ImageColor module.  If the color is\n",
       "   None, the image is not initialised.\n",
       ":returns: An :py:class:`~PIL.Image.Image` object.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\user\\anaconda3\\lib\\site-packages\\pil\\image.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = Image.new?\n",
    "#(mode='L', size=(height, width), color=255)\n",
    "\n",
    "    # Draw some lines\n",
    "#draw = ImageDraw.Draw?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
